{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["HXD0IkpAXv4M","s4_UtTIvY3Lg"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["##Get text for comparison"],"metadata":{"id":"u4vWT1YkX78C"}},{"cell_type":"code","source":["X =\"I love horror movies\"\n","Y =\"Lights out is a horror movie\""],"metadata":{"id":"g183qOgTYB6X"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Cosine similarity"],"metadata":{"id":"HXD0IkpAXv4M"}},{"cell_type":"code","source":["import nltk\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3L2XN91HX1AN","executionInfo":{"status":"ok","timestamp":1729183754688,"user_tz":-480,"elapsed":14490,"user":{"displayName":"Jacqueline Lam","userId":"04899815815415729021"}},"outputId":"f42c2c77-415f-4408-9645-a4efaf16545c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vTo1LKosWiHp"},"outputs":[],"source":["def consine_sim(X,Y):\n","\n","  # tokenization\n","  X_list = word_tokenize(X)\n","  Y_list = word_tokenize(Y)\n","\n","  # sw contains the list of stopwords\n","  sw = stopwords.words('english')\n","  l1 =[];l2 =[]\n","\n","  # remove stop words from the string\n","  X_set = {w for w in X_list if not w in sw}\n","  Y_set = {w for w in Y_list if not w in sw}\n","\n","  # form a set containing keywords of both strings\n","  rvector = X_set.union(Y_set)\n","  for w in rvector:\n","      if w in X_set: l1.append(1) # create a vector\n","      else: l1.append(0)\n","      if w in Y_set: l2.append(1)\n","      else: l2.append(0)\n","  c = 0\n","\n","  # cosine formula\n","  for i in range(len(rvector)):\n","          c+= l1[i]*l2[i]\n","  cosine = c / float((sum(l1)*sum(l2))**0.5)\n","\n","  return cosine"]},{"cell_type":"code","source":["consine_sim(X,Y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mw291lx1Ybjn","executionInfo":{"status":"ok","timestamp":1729183754689,"user_tz":-480,"elapsed":7,"user":{"displayName":"Jacqueline Lam","userId":"04899815815415729021"}},"outputId":"1a155603-24f3-4453-8c49-98cf755618f2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.2886751345948129"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["##NLP metrics"],"metadata":{"id":"s4_UtTIvY3Lg"}},{"cell_type":"code","source":["!pip install aac-metrics\n","!aac-metrics-download"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dgs5Rr-LY2VY","executionInfo":{"status":"ok","timestamp":1729184342730,"user_tz":-480,"elapsed":588046,"user":{"displayName":"Jacqueline Lam","userId":"04899815815415729021"}},"outputId":"1f2e4862-b066-498d-b10f-baea0272bbf7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting aac-metrics\n","  Downloading aac-metrics-0.5.4.tar.gz (161 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/161.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m143.4/161.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.8/161.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from aac-metrics) (1.26.4)\n","Requirement already satisfied: packaging>=23 in /usr/local/lib/python3.10/dist-packages (from aac-metrics) (24.1)\n","Requirement already satisfied: pyyaml>=6.0 in /usr/local/lib/python3.10/dist-packages (from aac-metrics) (6.0.2)\n","Collecting sentence-transformers>=2.2.2 (from aac-metrics)\n","  Downloading sentence_transformers-3.2.0-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: torch>=1.10.1 in /usr/local/lib/python3.10/dist-packages (from aac-metrics) (2.4.1+cu121)\n","Collecting torchmetrics>=0.11.4 (from aac-metrics)\n","  Downloading torchmetrics-1.4.3-py3-none-any.whl.metadata (19 kB)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from aac-metrics) (4.66.5)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from aac-metrics) (4.44.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.2.2->aac-metrics) (1.5.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.2.2->aac-metrics) (1.13.1)\n","Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.2.2->aac-metrics) (0.24.7)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.2.2->aac-metrics) (10.4.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.1->aac-metrics) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.1->aac-metrics) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.1->aac-metrics) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.1->aac-metrics) (3.4)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.1->aac-metrics) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.1->aac-metrics) (2024.6.1)\n","Collecting lightning-utilities>=0.8.0 (from torchmetrics>=0.11.4->aac-metrics)\n","  Downloading lightning_utilities-0.11.8-py3-none-any.whl.metadata (5.2 kB)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->aac-metrics) (2024.9.11)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->aac-metrics) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->aac-metrics) (0.4.5)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->aac-metrics) (0.19.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics>=0.11.4->aac-metrics) (71.0.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.1->aac-metrics) (3.0.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->aac-metrics) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->aac-metrics) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->aac-metrics) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->aac-metrics) (2024.8.30)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers>=2.2.2->aac-metrics) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers>=2.2.2->aac-metrics) (3.5.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.1->aac-metrics) (1.3.0)\n","Downloading sentence_transformers-3.2.0-py3-none-any.whl (255 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m255.2/255.2 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torchmetrics-1.4.3-py3-none-any.whl (869 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m869.5/869.5 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lightning_utilities-0.11.8-py3-none-any.whl (26 kB)\n","Building wheels for collected packages: aac-metrics\n","  Building wheel for aac-metrics (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for aac-metrics: filename=aac_metrics-0.5.4-py3-none-any.whl size=81166 sha256=b0fa8e713a67feb1016fa10544c699f9f1d6e8a43492673a3cc56cfaeb3fa659\n","  Stored in directory: /root/.cache/pip/wheels/ec/3d/e2/1d7cc3036cd832bf4578448cb62aa3fcd2132a61edc2b95f8f\n","Successfully built aac-metrics\n","Installing collected packages: lightning-utilities, torchmetrics, sentence-transformers, aac-metrics\n","Successfully installed aac-metrics-0.5.4 lightning-utilities-0.11.8 sentence-transformers-3.2.0 torchmetrics-1.4.3\n","2024-10-17 16:49:56.161622: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-10-17 16:49:56.213760: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-10-17 16:49:56.228179: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-10-17 16:49:56.261394: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-10-17 16:49:59.049982: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","[2024-10-17 16:50:02,347][aac_metrics.download][INFO] - aac-metrics download started.\n","[2024-10-17 16:50:02,347][aac_metrics.download][INFO] - Downloading JAR source for 'stanford_nlp' in directory /root/.cache/aac-metrics/stanford_nlp.\n","100% 5.65M/5.65M [00:00<00:00, 65.9MB/s]\n","[2024-10-17 16:50:03,175][aac_metrics.download][INFO] - Downloading source for 'meteor-1.5.jar' in directory /root/.cache/aac-metrics/meteor.\n","100% 6.03M/6.03M [00:00<00:00, 69.3MB/s]\n","[2024-10-17 16:50:03,741][aac_metrics.download][INFO] - Downloading source for 'data/paraphrase-en.gz' in directory /root/.cache/aac-metrics/meteor.\n","100% 58.9M/58.9M [00:00<00:00, 222MB/s]\n","[2024-10-17 16:50:05,101][aac_metrics.download][INFO] - Downloading source for 'data/paraphrase-fr.gz' in directory /root/.cache/aac-metrics/meteor.\n","100% 31.4M/31.4M [00:00<00:00, 199MB/s]\n","[2024-10-17 16:50:06,004][aac_metrics.download][INFO] - Downloading source for 'data/paraphrase-de.gz' in directory /root/.cache/aac-metrics/meteor.\n","100% 32.9M/32.9M [00:00<00:00, 204MB/s] \n","[2024-10-17 16:50:06,867][aac_metrics.download][INFO] - Downloading source for 'data/paraphrase-es.gz' in directory /root/.cache/aac-metrics/meteor.\n","100% 55.8M/55.8M [00:00<00:00, 146MB/s]\n","[2024-10-17 16:50:08,092][aac_metrics.download][INFO] - Downloading source for 'data/paraphrase-cz.gz' in directory /root/.cache/aac-metrics/meteor.\n","100% 7.40M/7.40M [00:00<00:00, 79.0MB/s]\n","[2024-10-17 16:50:08,701][aac_metrics.download][INFO] - Downloading file '/root/.cache/aac-metrics/spice/SPICE-1.0.zip' for SPICE...\n","100% 29.3M/29.3M [00:00<00:00, 133MB/s]\n","[2024-10-17 16:50:09,499][aac_metrics.download][INFO] - Extracting SPICE-1.0.zip to /root/.cache/aac-metrics/spice...\n","[2024-10-17 16:50:09,674][aac_metrics.download][INFO] - Downloading file '/root/.cache/aac-metrics/spice/SPICE-1.0/stanford-corenlp-full-2015-12-09.zip' for SPICE...\n","100% 384M/384M [08:12<00:00, 819kB/s]\n","[2024-10-17 16:58:22,617][aac_metrics.download][INFO] - Extracting SPICE-1.0/stanford-corenlp-full-2015-12-09.zip to /root/.cache/aac-metrics/spice...\n","[2024-10-17 16:58:24,824][aac_metrics.download][INFO] - Moving '/root/.cache/aac-metrics/spice/SPICE-1.0/spice-1.0.jar' to '/root/.cache/aac-metrics/spice'... (1/20)\n","[2024-10-17 16:58:24,824][aac_metrics.download][INFO] - Moving '/root/.cache/aac-metrics/spice/stanford-corenlp-full-2015-12-09/stanford-corenlp-3.6.0.jar' to '/root/.cache/aac-metrics/spice/lib'... (2/20)\n","[2024-10-17 16:58:24,824][aac_metrics.download][INFO] - Moving '/root/.cache/aac-metrics/spice/stanford-corenlp-full-2015-12-09/stanford-corenlp-3.6.0-models.jar' to '/root/.cache/aac-metrics/spice/lib'... (3/20)\n","[2024-10-17 16:58:24,825][aac_metrics.download][INFO] - Moving '/root/.cache/aac-metrics/spice/SPICE-1.0/lib/lmdbjni-win64-0.4.6.jar' to '/root/.cache/aac-metrics/spice/lib'... (4/20)\n","[2024-10-17 16:58:24,825][aac_metrics.download][INFO] - Moving '/root/.cache/aac-metrics/spice/SPICE-1.0/lib/SceneGraphParser-1.0.jar' to '/root/.cache/aac-metrics/spice/lib'... (5/20)\n","[2024-10-17 16:58:24,825][aac_metrics.download][INFO] - Moving '/root/.cache/aac-metrics/spice/SPICE-1.0/lib/lmdbjni-linux64-0.4.6.jar' to '/root/.cache/aac-metrics/spice/lib'... (6/20)\n","[2024-10-17 16:58:24,825][aac_metrics.download][INFO] - Moving '/root/.cache/aac-metrics/spice/SPICE-1.0/lib/ejml-0.23.jar' to '/root/.cache/aac-metrics/spice/lib'... (7/20)\n","[2024-10-17 16:58:24,825][aac_metrics.download][INFO] - Moving '/root/.cache/aac-metrics/spice/SPICE-1.0/lib/fst-2.47.jar' to '/root/.cache/aac-metrics/spice/lib'... (8/20)\n","[2024-10-17 16:58:24,825][aac_metrics.download][INFO] - Moving '/root/.cache/aac-metrics/spice/SPICE-1.0/lib/guava-19.0.jar' to '/root/.cache/aac-metrics/spice/lib'... (9/20)\n","[2024-10-17 16:58:24,826][aac_metrics.download][INFO] - Moving '/root/.cache/aac-metrics/spice/SPICE-1.0/lib/Meteor-1.5.jar' to '/root/.cache/aac-metrics/spice/lib'... (10/20)\n","[2024-10-17 16:58:24,826][aac_metrics.download][INFO] - Moving '/root/.cache/aac-metrics/spice/SPICE-1.0/lib/lmdbjni-osx64-0.4.6.jar' to '/root/.cache/aac-metrics/spice/lib'... (11/20)\n","[2024-10-17 16:58:24,826][aac_metrics.download][INFO] - Moving '/root/.cache/aac-metrics/spice/SPICE-1.0/lib/hamcrest-core-1.3.jar' to '/root/.cache/aac-metrics/spice/lib'... (12/20)\n","[2024-10-17 16:58:24,826][aac_metrics.download][INFO] - Moving '/root/.cache/aac-metrics/spice/SPICE-1.0/lib/junit-4.12.jar' to '/root/.cache/aac-metrics/spice/lib'... (13/20)\n","[2024-10-17 16:58:24,826][aac_metrics.download][INFO] - Moving '/root/.cache/aac-metrics/spice/SPICE-1.0/lib/json-simple-1.1.1.jar' to '/root/.cache/aac-metrics/spice/lib'... (14/20)\n","[2024-10-17 16:58:24,826][aac_metrics.download][INFO] - Moving '/root/.cache/aac-metrics/spice/SPICE-1.0/lib/jackson-core-2.5.3.jar' to '/root/.cache/aac-metrics/spice/lib'... (15/20)\n","[2024-10-17 16:58:24,826][aac_metrics.download][INFO] - Moving '/root/.cache/aac-metrics/spice/SPICE-1.0/lib/lmdbjni-0.4.6.jar' to '/root/.cache/aac-metrics/spice/lib'... (16/20)\n","[2024-10-17 16:58:24,826][aac_metrics.download][INFO] - Moving '/root/.cache/aac-metrics/spice/SPICE-1.0/lib/slf4j-api-1.7.12.jar' to '/root/.cache/aac-metrics/spice/lib'... (17/20)\n","[2024-10-17 16:58:24,827][aac_metrics.download][INFO] - Moving '/root/.cache/aac-metrics/spice/SPICE-1.0/lib/slf4j-simple-1.7.21.jar' to '/root/.cache/aac-metrics/spice/lib'... (18/20)\n","[2024-10-17 16:58:24,827][aac_metrics.download][INFO] - Moving '/root/.cache/aac-metrics/spice/SPICE-1.0/lib/objenesis-2.4.jar' to '/root/.cache/aac-metrics/spice/lib'... (19/20)\n","[2024-10-17 16:58:24,827][aac_metrics.download][INFO] - Moving '/root/.cache/aac-metrics/spice/SPICE-1.0/lib/javassist-3.19.0-GA.jar' to '/root/.cache/aac-metrics/spice/lib'... (20/20)\n","[2024-10-17 16:58:24,983][aac_metrics.download][INFO] - Downloading SBERT and BERT error detector for FENSE metric...\n","modules.json: 100% 229/229 [00:00<00:00, 1.20MB/s]\n","config_sentence_transformers.json: 100% 122/122 [00:00<00:00, 568kB/s]\n","README.md: 100% 3.74k/3.74k [00:00<00:00, 19.3MB/s]\n","sentence_bert_config.json: 100% 53.0/53.0 [00:00<00:00, 219kB/s]\n","config.json: 100% 631/631 [00:00<00:00, 3.79MB/s]\n","model.safetensors: 100% 268M/268M [00:04<00:00, 61.2MB/s]\n","tokenizer_config.json: 100% 531/531 [00:00<00:00, 2.73MB/s]\n","vocab.txt: 100% 232k/232k [00:00<00:00, 5.76MB/s]\n","tokenizer.json: 100% 466k/466k [00:00<00:00, 22.7MB/s]\n","special_tokens_map.json: 100% 112/112 [00:00<00:00, 481kB/s]\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n","1_Pooling/config.json: 100% 190/190 [00:00<00:00, 1.21MB/s]\n","100% 438M/438M [00:06<00:00, 63.1MB/s]\n","/usr/local/lib/python3.10/dist-packages/aac_metrics/functional/fer.py:392: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model_states = torch.load(file_path)\n","config.json: 100% 570/570 [00:00<00:00, 2.19MB/s]\n","model.safetensors: 100% 440M/440M [00:02<00:00, 170MB/s]\n","tokenizer_config.json: 100% 48.0/48.0 [00:00<00:00, 192kB/s]\n","vocab.txt: 100% 232k/232k [00:00<00:00, 137MB/s]\n","tokenizer.json: 100% 466k/466k [00:00<00:00, 14.3MB/s]\n","[2024-10-17 16:58:45,464][aac_metrics.download][INFO] - Downloading BERT model for BERTScore metric...\n","tokenizer_config.json: 100% 25.0/25.0 [00:00<00:00, 155kB/s]\n","config.json: 100% 482/482 [00:00<00:00, 2.50MB/s]\n","vocab.json: 100% 899k/899k [00:00<00:00, 30.7MB/s]\n","merges.txt: 100% 456k/456k [00:00<00:00, 58.9MB/s]\n","tokenizer.json: 100% 1.36M/1.36M [00:00<00:00, 35.0MB/s]\n","model.safetensors: 100% 1.42G/1.42G [00:12<00:00, 117MB/s]\n","[2024-10-17 16:58:58,739][aac_metrics.download][INFO] - aac-metrics download finished.\n"]}]},{"cell_type":"code","source":["from aac_metrics import evaluate"],"metadata":{"id":"lzqhkaKyaO1J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def nlp_score(X,Y, metric_name):\n","\n","  actual=[]\n","  predicted=[]\n","\n","  for i in range(5):\n","    actual.append(X)\n","    predicted.append(Y)\n","\n","  # calculate evaluation score\n","  ##input: list(), list(list(str))\n","  ##output: dict containing the score of each metric: \"bleu_1\", \"bleu_2\", \"bleu_3\", \"bleu_4\", \"rouge_l\", \"meteor\", \"cider_d\", \"spice\", \"spider\"\n","\n","  corpus_scores, _ = evaluate([item for item in predicted], [[item] for item in actual])\n","\n","  return corpus_scores[metric_name]"],"metadata":{"id":"ihoFV9TjZ4Ye"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nlp_score(X,Y, \"spice\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1WUfcBThY_Yp","executionInfo":{"status":"ok","timestamp":1729184796262,"user_tz":-480,"elapsed":28218,"user":{"displayName":"Jacqueline Lam","userId":"04899815815415729021"}},"outputId":"c038517f-9640-4e55-fc12-62a3cb1128db"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(0.5000, dtype=torch.float64)"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["# calculate evaluation score\n","##input: list(), list(list(str))\n","##output: dict containing the score of each metric: \"bleu_1\", \"bleu_2\", \"bleu_3\", \"bleu_4\", \"rouge_l\", \"meteor\", \"cider_d\", \"spice\", \"spider\"\n","\n","# corpus_scores, _ = evaluate([item for item in predicted], [[item] for item in actual])\n","# print(corpus_scores)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2CLd6BYSZtnt","executionInfo":{"status":"ok","timestamp":1728211403231,"user_tz":-480,"elapsed":32398,"user":{"displayName":"Jacqueline Lam","userId":"04899815815415729021"}},"outputId":"cc39d162-619f-4bc7-d076-5bc57aabe50e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'bleu_1': tensor(0.1667, dtype=torch.float64), 'bleu_2': tensor(1.8257e-09, dtype=torch.float64), 'bleu_3': tensor(4.3679e-12, dtype=torch.float64), 'bleu_4': tensor(2.2957e-13, dtype=torch.float64), 'meteor': tensor(0.2226, dtype=torch.float64), 'rouge_l': tensor(0.2075, dtype=torch.float64), 'cider_d': tensor(0., dtype=torch.float64), 'spice': tensor(0.5000, dtype=torch.float64), 'spider': tensor(0.2500, dtype=torch.float64)}\n"]}]},{"cell_type":"markdown","source":["## Cosine Similarity (Embedding)"],"metadata":{"id":"MwBWMzxg4O_V"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ctw1SEwV4pjz"},"outputs":[],"source":["import random\n","from transformers import BertTokenizer, BertModel\n","from sklearn.metrics.pairwise import cosine_similarity"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":177,"referenced_widgets":["efd767eea6b2456dad2e7959785b061a","b1787189801d4b45b62f2b9c740ed5db","4711135a7883404c96e73544264dd5eb","24e15cdce7a2424ab49ba6480fb3508b","14d2f9b6906a41a0b7c55398e4deb599","40789144d5894447bcf4fb3728ccc9f6","bb8c4c69d22e4354a9233bd6f1c2435e","033dd6303aef455da4dd551a6706c802","ad15898deb4a44ee962d5ae547c6fb7d","915d6f8e4c864bbd88e971c5216ee6ba","78cff331b94a4ae7b59070391a75cd43","f465e6e8b8754cfd9ed86dcbe4374d1a","8e2cbf13406443aaa098d0aa4ce10ebe","83519759d597415da71bef7e3038d428","36e5c23908b14b5c94afaa4b7ccab63e","4837764785bf40e6a58b42c3b560a96c","5253781eedc142d48295ec9c91db6276","1c572d20f6c84eb3968dac39cbee2caa","2f9bbf44e377410daa409505a5621583","883e5aa35eec4fafad4bc90e87ecaa4f","fb07e82ad17f4f428dce2b511afcb58a","54dc843d699c4a32888ea872cdec35ad","d6c4d322ad324eb88d03791f765148d6","7f8a10a9940340afa7ea0d3e0781a68a","2b4803e5f77a4749b72b24c6e764a46e","ebdadb695d2d4550a41847847550d72a","9092bfb7194441fc825399f52fb20ef0","f052c1d8948344788d181c88a72c4032","322a873dfd774577abcfd2ce8a80eb05","006dfc5ab10a44dea5842c404b5d68cf","dc8195a47dea4401b6903cf9111b2fd3","e1e141e990924584a3284bc6be9178e4","8f6e6ad82b734251916260d53f1849db","092d8bd098cd437fbf8003101f83d9b4","59eecd1450654878a6a5d6a703e813d2","1d5a90aa6b1f4e278f0f68f134658f17","cbc612f1cf42451f887f32545e64d7ea","997bb1921f124a1a8a8e66765355feb2","aac310eb20b54d92a06beef4278f5cfd","f8414afe3f274bb898d307102bb9ed15","03872cd8f06c4c66a2f017ef19fe55d6","5968ec095f3848298b29dea4b27e6d9d","76df63e2c8b9418f8e5ba7005f8a3c46","3916a8cc99054c65adc621b6b11171d7","ca300b3d86fe40f9acf438507c4ef904","e4da29c7efdf4359b2a289f4431033fd","1cafc369d1454ab4bba98c55f8e181ac","5fc3dc830c744593b0b28e0d310a23d3","b7029c1f5a4446cb87d0460470286586","2a20a417455440faaace373e2965ce3b","c04bea4a95b346f69182cb5f08516b7c","42d6d33695264922abe0de98b8f412ce","a7c7065b4ccf46a88393bd9cfb147af0","1589c273309e470294eb23cc98da1a83","8f6bc8df091946c3b8f78861907a9e63"]},"executionInfo":{"status":"ok","timestamp":1730131180820,"user_tz":-480,"elapsed":6604,"user":{"displayName":"Jacqueline Lam","userId":"04899815815415729021"}},"outputId":"4ad87129-933f-452d-e404-fc334efa18e3","id":"B_Zdk3_f4pj0"},"outputs":[{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"efd767eea6b2456dad2e7959785b061a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f465e6e8b8754cfd9ed86dcbe4374d1a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6c4d322ad324eb88d03791f765148d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"092d8bd098cd437fbf8003101f83d9b4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca300b3d86fe40f9acf438507c4ef904"}},"metadata":{}}],"source":["# Set a random seed\n","random_seed = 42\n","random.seed(random_seed)\n","\n","# Set a random seed for PyTorch (for GPU as well)\n","torch.manual_seed(random_seed)\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed_all(random_seed)\n","\n","# Load BERT tokenizer and model\n","tokenizer_bert = BertTokenizer.from_pretrained('bert-base-uncased')\n","model_bert = BertModel.from_pretrained('bert-base-uncased')"]},{"cell_type":"code","source":["def bert_embedding(example_sentence, model=model_bert, tokenizer=tokenizer_bert):\n","\n","  # Tokenize and encode the example sentence\n","  example_encoding = tokenizer.batch_encode_plus(\n","      [example_sentence],\n","      padding=True,\n","      truncation=True,\n","      return_tensors='pt',\n","      add_special_tokens=True\n","  )\n","  example_input_ids = example_encoding['input_ids']\n","  example_attention_mask = example_encoding['attention_mask']\n","\n","  # Generate embeddings for the example sentence\n","  with torch.no_grad():\n","      example_outputs = model(example_input_ids, attention_mask=example_attention_mask)\n","      example_sentence_embedding = example_outputs.last_hidden_state.mean(dim=1)\n","\n","  return example_sentence_embedding"],"metadata":{"id":"yITL03CF2r5P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def consine_sim(a,b):\n","  similarity_score = cosine_similarity(bert_embedding(a), bert_embedding(b))[0][0]\n","  return similarity_score"],"metadata":{"id":"XWMOquUg3GPI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cosine_sim(X,Y)"],"metadata":{"id":"uZIm0skv4sWZ"},"execution_count":null,"outputs":[]}]}